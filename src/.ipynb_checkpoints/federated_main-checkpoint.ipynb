{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c65609f-63a2-4a64-bba2-b27a2e601e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Python version: 3.6\n",
    "\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import argparse\n",
    "from options import args_parser\n",
    "from update import LocalUpdate, test_inference\n",
    "from models import MLP, CNNMnist, CNNFashion_Mnist, CNNCifar\n",
    "from utils import get_dataset, average_weights, exp_details\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a204d617-f6ab-4248-b5f2-daad5da4ddf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here3\n",
      "here2\n",
      "\n",
      "Experimental details:\n",
      "    Model     : mlp\n",
      "    Optimizer : sgd\n",
      "    Learning  : 0.01\n",
      "    Global Rounds   : 10\n",
      "\n",
      "    Federated parameters:\n",
      "    IID\n",
      "    Fraction of users  : 0.1\n",
      "    Local Batch size   : 10\n",
      "    Local Epochs       : 10\n",
      "\n",
      "here1\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == '__main__':\n",
    "start_time = time.time()\n",
    "\n",
    "# define paths\n",
    "path_project = os.path.abspath('..')\n",
    "logger = SummaryWriter('../logs')\n",
    "print('here3')\n",
    "\n",
    "args = args_parser()\n",
    "print('here2')\n",
    "exp_details(args)\n",
    "print('here1')\n",
    "device = 'cuda' if args.gpu else 'cpu'\n",
    "\n",
    "if args.gpu:\n",
    "    torch.cuda.set_device(args.gpu)\n",
    "\n",
    "    \n",
    "    \n",
    "# load dataset and user groups\n",
    "train_dataset, test_dataset, user_groups = get_dataset(args)\n",
    "\n",
    "# BUILD MODEL\n",
    "if args.model == 'cnn':\n",
    "    # Convolutional neural netork\n",
    "    if args.dataset == 'mnist':\n",
    "        global_model = CNNMnist(args=args)\n",
    "    elif args.dataset == 'fmnist':\n",
    "        global_model = CNNFashion_Mnist(args=args)\n",
    "    elif args.dataset == 'cifar':\n",
    "        global_model = CNNCifar(args=args)\n",
    "\n",
    "elif args.model == 'mlp':\n",
    "    # Multi-layer preceptron\n",
    "    img_size = train_dataset[0][0].shape\n",
    "    len_in = 1\n",
    "    for x in img_size:\n",
    "        len_in *= x\n",
    "        global_model = MLP(dim_in=len_in, dim_hidden=64,\n",
    "                           dim_out=args.num_classes)\n",
    "else:\n",
    "    print('Error: unrecognized model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a6b0a4-345c-41f6-b804-7848a1320ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5475e4d7-d923-47bd-9676-728367fedf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# num_users=100\n",
    "# test=np.random.exponential(scale=1.0, size=num_users)\n",
    "# print(test)\n",
    "# plt.hist(test)\n",
    "# plt.show()\n",
    "# norm=np.random.normal(loc=1.19865, scale=1.0, size=num_users)\n",
    "# print(norm)\n",
    "# plt.plot(np.arange(norm.size),norm)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d0e4e3d-9c97-497f-9eba-d57302be9b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (-0.4242+2.8215)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f856bc7-3dc8-408e-bf0b-8273604a57d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gen_response_time(num_users=args.num_users):\n",
    "#     np.random.exponential(scale=1.0, size=num_users)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8b34fd6-cd2c-4499-a6e7-28972aef7af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (layer_input): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (layer_hidden): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " | Global Training Round : 1 |\n",
      "\n",
      "[19.43664992  5.24561408  1.99752981  9.25670477 12.28232634  0.40932905\n",
      "  4.7329129  15.18004028 13.8801674   0.12217642]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xin/Developer/CMPUT675_Project/src/update.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(image), torch.tensor(label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accu: 0.5833333333333334  test loss: -4.52642460167408\n",
      "test_accu: 0.5166666666666667  test loss: -3.625602275133133\n",
      "test_accu: 0.5666666666666667  test loss: -4.4148664474487305\n",
      "test_accu: 0.5166666666666667  test loss: -3.9206603094935417\n",
      "test_accu: 0.6666666666666666  test loss: -4.556306108832359\n",
      "test_accu: 0.6  test loss: -3.8230721950531006\n",
      "test_accu: 0.7  test loss: -4.624597579240799\n",
      "test_accu: 0.6  test loss: -4.609623461961746\n",
      "test_accu: 0.5666666666666667  test loss: -3.983491227030754\n",
      "test_accu: 0.6333333333333333  test loss: -5.078565552830696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▍                                       | 1/10 [00:17<02:33, 17.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " | Global Training Round : 2 |\n",
      "\n",
      "[ 2.43504622 32.31006996  3.68054334  2.83039113  5.65501104  2.88072407\n",
      "  3.19771186  7.79660727  4.49952701  3.53119628]\n",
      "test_accu: 0.7333333333333333  test loss: -6.287081390619278\n",
      "test_accu: 0.6166666666666667  test loss: -5.69814245402813\n",
      "test_accu: 0.7833333333333333  test loss: -6.925233036279678\n",
      "test_accu: 0.6666666666666666  test loss: -6.2375903725624084\n",
      "test_accu: 0.65  test loss: -5.643019497394562\n",
      "test_accu: 0.75  test loss: -6.437629133462906\n",
      "test_accu: 0.7833333333333333  test loss: -6.392435908317566\n",
      "test_accu: 0.7166666666666667  test loss: -6.327039837837219\n",
      "test_accu: 0.6666666666666666  test loss: -5.567442819476128\n",
      "test_accu: 0.7833333333333333  test loss: -6.801602810621262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▊                                   | 2/10 [00:34<02:19, 17.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Avg Training Stats after 2 global rounds:\n",
      "Training Loss : -0.4447830911640389\n",
      "Train Accuracy: 76.67% \n",
      "\n",
      "\n",
      " | Global Training Round : 3 |\n",
      "\n",
      "[17.01768598 21.20745675  7.41069614  9.62617275  1.43356993  5.44447653\n",
      "  1.04917471 18.8573975   8.29654526  9.3463738 ]\n",
      "test_accu: 0.7333333333333333  test loss: -6.812283635139465\n",
      "test_accu: 0.7333333333333333  test loss: -6.600163638591766\n",
      "test_accu: 0.7666666666666667  test loss: -6.984232097864151\n",
      "test_accu: 0.7166666666666667  test loss: -6.5223568975925446\n",
      "test_accu: 0.7833333333333333  test loss: -7.068280965089798\n",
      "test_accu: 0.6666666666666666  test loss: -6.117493838071823\n",
      "test_accu: 0.7666666666666667  test loss: -6.935024529695511\n",
      "test_accu: 0.8166666666666667  test loss: -7.51274636387825\n",
      "test_accu: 0.6666666666666666  test loss: -6.455796182155609\n",
      "test_accu: 0.65  test loss: -6.171280056238174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████▏                              | 3/10 [00:52<02:03, 17.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " | Global Training Round : 4 |\n",
      "\n",
      "[ 2.80733407 12.11126525  1.11738303  9.28162249 11.35441953  5.29870886\n",
      "  3.48765346 74.50189211  1.33374703  3.69284143]\n",
      "test_accu: 0.75  test loss: -7.14656075835228\n",
      "test_accu: 0.6666666666666666  test loss: -6.467934876680374\n",
      "test_accu: 0.75  test loss: -7.482643038034439\n",
      "test_accu: 0.7333333333333333  test loss: -6.824639737606049\n",
      "test_accu: 0.7833333333333333  test loss: -7.2864677011966705\n",
      "test_accu: 0.6833333333333333  test loss: -6.459668189287186\n",
      "test_accu: 0.6666666666666666  test loss: -6.427355200052261\n",
      "test_accu: 0.7166666666666667  test loss: -6.827208310365677\n",
      "test_accu: 0.7666666666666667  test loss: -7.157358348369598\n",
      "test_accu: 0.7833333333333333  test loss: -7.305462121963501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▌                          | 4/10 [01:10<01:45, 17.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Avg Training Stats after 4 global rounds:\n",
      "Training Loss : -0.5561605372958972\n",
      "Train Accuracy: 76.67% \n",
      "\n",
      "\n",
      " | Global Training Round : 5 |\n",
      "\n",
      "[29.86473527  2.40180874  5.26760076  7.35201722 19.86283801  6.81368939\n",
      " 18.87018152  4.6352778   0.75534287 25.63831494]\n",
      "test_accu: 0.7166666666666667  test loss: -6.878698647022247\n",
      "test_accu: 0.7833333333333333  test loss: -7.357741743326187\n",
      "test_accu: 0.6333333333333333  test loss: -6.012513369321823\n",
      "test_accu: 0.6833333333333333  test loss: -6.5505392253398895\n",
      "test_accu: 0.7166666666666667  test loss: -6.784014582633972\n",
      "test_accu: 0.75  test loss: -7.219985753297806\n",
      "test_accu: 0.75  test loss: -7.24525511264801\n",
      "test_accu: 0.7  test loss: -6.7004921436309814\n",
      "test_accu: 0.6666666666666666  test loss: -6.522599995136261\n",
      "test_accu: 0.7  test loss: -6.74362912774086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████                      | 5/10 [01:29<01:30, 18.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " | Global Training Round : 6 |\n",
      "\n",
      "[12.38565356  2.04630001 16.34554708  1.86184991  5.55337978 12.54007449\n",
      "  5.38989749  6.95239428 19.16283095  4.83984405]\n",
      "test_accu: 0.8166666666666667  test loss: -7.710614264011383\n",
      "test_accu: 0.65  test loss: -6.635696709156036\n",
      "test_accu: 0.75  test loss: -7.263065367937088\n",
      "test_accu: 0.7166666666666667  test loss: -7.052247047424316\n",
      "test_accu: 0.7166666666666667  test loss: -6.5788819789886475\n",
      "test_accu: 0.6833333333333333  test loss: -6.576337575912476\n",
      "test_accu: 0.7  test loss: -6.7369778752326965\n",
      "test_accu: 0.6166666666666667  test loss: -6.0546590983867645\n",
      "test_accu: 0.6666666666666666  test loss: -6.430259108543396\n",
      "test_accu: 0.7  test loss: -6.953902214765549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████▍                 | 6/10 [01:46<01:10, 17.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Avg Training Stats after 6 global rounds:\n",
      "Training Loss : -0.601556626579776\n",
      "Train Accuracy: 73.33% \n",
      "\n",
      "\n",
      " | Global Training Round : 7 |\n",
      "\n",
      "[ 9.17179536  7.42939711  2.04710428  6.80284315  5.26287423  7.33956395\n",
      "  1.65709924  7.67295498  1.68483537 13.18129465]\n",
      "test_accu: 0.7333333333333333  test loss: -6.973761856555939\n",
      "test_accu: 0.65  test loss: -6.367091119289398\n",
      "test_accu: 0.7  test loss: -6.814153403043747\n",
      "test_accu: 0.7333333333333333  test loss: -7.0779619216918945\n",
      "test_accu: 0.7  test loss: -6.73729994893074\n",
      "test_accu: 0.6166666666666667  test loss: -5.914827033877373\n",
      "test_accu: 0.8166666666666667  test loss: -7.780009061098099\n",
      "test_accu: 0.6333333333333333  test loss: -6.139779359102249\n",
      "test_accu: 0.65  test loss: -6.549240380525589\n",
      "test_accu: 0.6666666666666666  test loss: -6.634836554527283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████▊             | 7/10 [02:03<00:52, 17.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " | Global Training Round : 8 |\n",
      "\n",
      "[1.65851619e-02 3.71435078e+00 1.91287199e+01 8.60843241e-03\n",
      " 3.74048344e+01 1.45712536e+00 2.32206263e+01 5.64623841e+00\n",
      " 2.83202662e+00 2.14069577e+01]\n",
      "test_accu: 0.7166666666666667  test loss: -6.833587110042572\n",
      "test_accu: 0.75  test loss: -7.085980236530304\n",
      "test_accu: 0.7166666666666667  test loss: -7.03568297624588\n",
      "test_accu: 0.7333333333333333  test loss: -6.80446070432663\n",
      "test_accu: 0.6666666666666666  test loss: -6.658242583274841\n",
      "test_accu: 0.7333333333333333  test loss: -6.97353957593441\n",
      "test_accu: 0.6666666666666666  test loss: -6.359981268644333\n",
      "test_accu: 0.7  test loss: -6.5378279983997345\n",
      "test_accu: 0.7166666666666667  test loss: -6.966520309448242\n",
      "test_accu: 0.6666666666666666  test loss: -6.425195619463921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████▏        | 8/10 [02:22<00:35, 17.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Avg Training Stats after 8 global rounds:\n",
      "Training Loss : -0.6280152971854356\n",
      "Train Accuracy: 65.00% \n",
      "\n",
      "\n",
      " | Global Training Round : 9 |\n",
      "\n",
      "[10.28519426  7.11673776  2.16724851  6.04657988  9.05542301  0.82745124\n",
      " 29.05196837  0.04845718  6.491628   13.91748486]\n",
      "test_accu: 0.8  test loss: -7.675090402364731\n",
      "test_accu: 0.6833333333333333  test loss: -6.730413913726807\n",
      "test_accu: 0.6166666666666667  test loss: -6.291409030556679\n",
      "test_accu: 0.65  test loss: -6.398808404803276\n",
      "test_accu: 0.6833333333333333  test loss: -6.5837893187999725\n",
      "test_accu: 0.7666666666666667  test loss: -7.3355569541454315\n",
      "test_accu: 0.7166666666666667  test loss: -6.892765134572983\n",
      "test_accu: 0.7333333333333333  test loss: -6.975696086883545\n",
      "test_accu: 0.75  test loss: -7.165067136287689\n",
      "test_accu: 0.8166666666666667  test loss: -7.884669840335846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████▌    | 9/10 [02:42<00:18, 18.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " | Global Training Round : 10 |\n",
      "\n",
      "[ 2.61342796  2.98443309  1.27011022  2.46955366  3.50412942 32.32801202\n",
      "  2.09909847  5.11545639 11.59641641  0.08857442]\n",
      "test_accu: 0.75  test loss: -7.399089217185974\n",
      "test_accu: 0.6166666666666667  test loss: -6.441010028123856\n",
      "test_accu: 0.7833333333333333  test loss: -7.427319794893265\n",
      "test_accu: 0.65  test loss: -6.410510405898094\n",
      "test_accu: 0.65  test loss: -6.267199218273163\n",
      "test_accu: 0.7833333333333333  test loss: -7.5494765639305115\n",
      "test_accu: 0.6333333333333333  test loss: -6.240287721157074\n",
      "test_accu: 0.8166666666666667  test loss: -7.999426782131195\n",
      "test_accu: 0.6666666666666666  test loss: -6.468034595251083\n",
      "test_accu: 0.8166666666666667  test loss: -8.063801229000092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [03:02<00:00, 18.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Avg Training Stats after 10 global rounds:\n",
      "Training Loss : -0.6451344507477867\n",
      "Train Accuracy: 81.67% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the model to train and send it to device.\n",
    "global_model.to(device)\n",
    "global_model.train()\n",
    "print(global_model)\n",
    "\n",
    "# copy weights\n",
    "global_weights = global_model.state_dict()\n",
    "\n",
    "# Training\n",
    "train_loss, train_accuracy = [], []\n",
    "val_acc_list, net_list = [], []\n",
    "cv_loss, cv_acc = [], []\n",
    "print_every = 2\n",
    "val_loss_pre, counter = 0, 0\n",
    "res_times_epochs = []\n",
    "selected_user_idxs_epochs=[]\n",
    "average_time_epochs=[]\n",
    "test_accs_epochs=[]\n",
    "noise_levels_epochs=[]\n",
    "seed=20\n",
    "max_time_epochs=[]\n",
    "# np.random.seed(seed)\n",
    "\n",
    "for epoch in tqdm(range(args.epochs)):\n",
    "    test_accs=[]\n",
    "    local_weights, local_losses = [], []\n",
    "    print(f'\\n | Global Training Round : {epoch+1} |\\n')\n",
    "    res_times=np.random.exponential(scale=10, size=args.num_users)\n",
    "    res_times_epochs.append(res_times)\n",
    "    print(res_times[:10])\n",
    "    noise_levels = np.random.uniform(low=0, high=1, size=args.num_users) # noise level for norm dist, 0 mean, this is var\n",
    "    noise_levels_epochs.append(noise_levels)\n",
    "    global_model.train()\n",
    "    # m = max(int(args.frac * args.num_users), 1)\n",
    "    m = 10\n",
    "\n",
    "    idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n",
    "    selected_user_idxs_epochs.append(idxs_users)\n",
    "    for idx in idxs_users:\n",
    "        local_model = LocalUpdate(args=args, dataset=train_dataset,\n",
    "                                  idxs=user_groups[idx], logger=logger, noise_level=noise_levels[idx], seed=seed)\n",
    "        w, loss, test_acc = local_model.update_weights(\n",
    "            model=copy.deepcopy(global_model), global_round=epoch)\n",
    "        local_weights.append(copy.deepcopy(w))\n",
    "        local_losses.append(copy.deepcopy(loss))\n",
    "        test_accs.append(test_acc)\n",
    "    test_accs_epochs.append(test_accs)\n",
    "    \n",
    "    average_time=0\n",
    "    max_time=0\n",
    "    for idx in idxs_users:\n",
    "        average_time+=res_times[idx]\n",
    "        max_time = max(max_time, res_times[idx])\n",
    "    \n",
    "    average_time = average_time/len(idxs_users)\n",
    "    average_time_epochs.append(average_time)\n",
    "    max_time_epochs.append(max_time)\n",
    "    # update global weights\n",
    "    global_weights = average_weights(local_weights)\n",
    "\n",
    "    # update global weights\n",
    "    global_model.load_state_dict(global_weights)\n",
    "\n",
    "    loss_avg = sum(local_losses) / len(local_losses)\n",
    "    train_loss.append(loss_avg)\n",
    "\n",
    "    # Calculate avg training accuracy over all users at every epoch\n",
    "    list_acc, list_loss = [], []\n",
    "    global_model.eval()\n",
    "    for c in range(args.num_users):\n",
    "        local_model = LocalUpdate(args=args, dataset=train_dataset,\n",
    "                                  idxs=user_groups[idx], logger=logger, noise_level=noise_levels[idx], seed=seed)\n",
    "        acc, loss = local_model.inference(model=global_model)\n",
    "        list_acc.append(acc)\n",
    "        list_loss.append(loss)\n",
    "    train_accuracy.append(sum(list_acc)/len(list_acc))\n",
    "\n",
    "    # print global training loss after every 'i' rounds\n",
    "    if (epoch+1) % print_every == 0:\n",
    "        print(f' \\nAvg Training Stats after {epoch+1} global rounds:')\n",
    "        print(f'Training Loss : {np.mean(np.array(train_loss))}')\n",
    "        print('Train Accuracy: {:.2f}% \\n'.format(100*train_accuracy[-1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20762342-1a2b-499e-a6c6-051cde869b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Results after 10 global rounds of training:\n",
      "|---- Avg Train Accuracy: 81.67%\n",
      "|---- Test Accuracy: 73.20%\n",
      "\n",
      " Total Run Time: 185.2656\n",
      "10.437060335765855\n",
      "34.76089163164503\n"
     ]
    }
   ],
   "source": [
    "# Test inference after completion of training\n",
    "test_acc, test_loss = test_inference(args, global_model, test_dataset)\n",
    "\n",
    "print(f' \\n Results after {args.epochs} global rounds of training:')\n",
    "print(\"|---- Avg Train Accuracy: {:.2f}%\".format(100*train_accuracy[-1]))\n",
    "print(\"|---- Test Accuracy: {:.2f}%\".format(100*test_acc))\n",
    "\n",
    "# Saving the objects train_loss and train_accuracy:\n",
    "file_name = '../save/objects/{}_{}_{}_C[{}]_iid[{}]_E[{}]_B[{}].pkl'.\\\n",
    "    format(args.dataset, args.model, args.epochs, args.frac, args.iid,\n",
    "           args.local_ep, args.local_bs)\n",
    "\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump([train_loss, train_accuracy], f)\n",
    "\n",
    "print('\\n Total Run Time: {0:0.4f}'.format(time.time()-start_time))\n",
    "\n",
    "print(np.mean(average_time_epochs))\n",
    "print(np.mean(max_time_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86b90fe9-c941-465b-bb59-811f84224039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.407564811354465, 9.334892118546424, 13.482894581917837, 14.831306653150545, 9.117553306114354, 6.297798137677307, 9.216626866356295, 11.06767136851954, 12.501305752386099, 10.112989761635689]\n",
      "[20.53173557889863, 40.694375192113306, 37.5604733492251, 74.5018921070958, 18.870181518176427, 14.297487385948397, 32.41453638841938, 44.441746476542725, 39.37000624735798, 24.92648207267258]\n"
     ]
    }
   ],
   "source": [
    "print(average_time_epochs)\n",
    "print(max_time_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cefad019-8e46-4098-9291-d7d3541afecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING (optional)\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "\n",
    "# Plot Loss curve\n",
    "# plt.figure()\n",
    "# plt.title('Training Loss vs Communication rounds')\n",
    "# plt.plot(range(len(train_loss)), train_loss, color='r')\n",
    "# plt.ylabel('Training loss')\n",
    "# plt.xlabel('Communication Rounds')\n",
    "# plt.savefig('../save/fed_{}_{}_{}_C[{}]_iid[{}]_E[{}]_B[{}]_loss.png'.\n",
    "#             format(args.dataset, args.model, args.epochs, args.frac,\n",
    "#                    args.iid, args.local_ep, args.local_bs))\n",
    "#\n",
    "# # Plot Average Accuracy vs Communication rounds\n",
    "# plt.figure()\n",
    "# plt.title('Average Accuracy vs Communication rounds')\n",
    "# plt.plot(range(len(train_accuracy)), train_accuracy, color='k')\n",
    "# plt.ylabel('Average Accuracy')\n",
    "# plt.xlabel('Communication Rounds')\n",
    "# plt.savefig('../save/fed_{}_{}_{}_C[{}]_iid[{}]_E[{}]_B[{}]_acc.png'.\n",
    "#             format(args.dataset, args.model, args.epochs, args.frac,\n",
    "#                    args.iid, args.local_ep, args.local_bs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe6dee27-c8f4-492c-b306-d5b9fef9f0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.516"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(79.39+73.32+70.74+76.65+77.48)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3558dc26-1f43-4b7d-a46b-3931311f4868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294.00000000000006"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(100/30+15*15/60+800/60)/5*72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "701533e6-5964-4bb5-a7c6-1ac78f9ff6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.62499999999997"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "214.0625/15/(2*(1-13.75/15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6883a199-f74c-4344-b823-febe87feeb72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.375"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5 * 95.625 + 0.25 * 100.625 + 0.25 *105.625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2994d17-ea86-4344-8d69-26883c554a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104.09375"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5  *  25.3125 + 0.25  *51.75 + 0.25  *314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b32c089-388d-4012-93c8-a8aa52944605",
   "metadata": {},
   "outputs": [],
   "source": [
    "(100/30+15*15/60)/5*9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91b500df-13d4-47ea-a08b-8c22da186dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.62499999999996"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13.75*13.75/15/(2*(1-13.75/15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f743b2ab-c13b-4c0b-b393-ea01885076b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.09375"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5 * 15.3125 + 0.25 *27.75 + 0.25 *342"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d4e3dbe-b5d7-46c5-81d6-35951c707e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.75"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5*10+0.25*15+ 0.25*20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0529258f-2202-426c-825b-f445cad3ebef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
